{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Implementation of EEGLearn - P. Bashivan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes a short summary of Pytorch implementation of the models described in \"Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks.\" Bashivan et al. at International conference on learning representations (2016).\n",
    "\n",
    "The rest of the code is in the different python scripts of this repo.\n",
    "\n",
    "All the codes have been inspired from the [original github](https://github.com/pbashivan/EEGLearn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import os \n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "\n",
    "from Utils import *\n",
    "from Models import *\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We adopted a recurrent-convolutional neural network to deal with the inherent structure of EEG data.\n",
    "ConvNets were used to deal with variations in space and frequency domains due to their ability to\n",
    "learn good two-dimensional representation of the data. Wherever needed, the extracted representations were fed into another layer to account for temporal variations in the data. We evaluated various\n",
    "types of layers used for extracting temporal patterns, including convolutional and recurrent layers.\n",
    "Essentially, we evaluated the following two primary approaches to the cognitive state classification problem.\n",
    "\n",
    "1) Single-frame approach: a single image was constructed from spectral measurements\n",
    "over the complete trial duration. The constructed image was then used as input to the ConvNet.\n",
    "\n",
    "2)\n",
    "Multi-frame approach: We divided each trial into 0.5 second windows and constructed an image over each time window, delivering 7 frames per trial (see section 4). The sequence of images was then used as input data to the recurrent-convolutional network. We used Lasagne1 to implement different architectures discussed in this paper. The code necessary for generating EEG images and building and training the networks discussed in this paper is available online2\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the original Images \n",
    "The images have directly been taken from original implementation, given that they remain the same nevermind the implementation (Pytorch, Tensorflow, Theano)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2670, 3, 32, 32)\n",
      "(7, 2670, 3, 32, 32)\n",
      "(2670,)\n",
      "(2670,)\n"
     ]
    }
   ],
   "source": [
    "Mean_Images = sio.loadmat(\"Sample Data/images.mat\")[\"img\"] #corresponding to the images mean for all the seven windows\n",
    "print(np.shape(Mean_Images)) \n",
    "Images = sio.loadmat(\"Sample Data/images_time.mat\")[\"img\"] #corresponding to the images mean for all the seven windows\n",
    "print(np.shape(Images)) \n",
    "Label = (sio.loadmat(\"Sample Data/FeatureMat_timeWin\")[\"features\"][:,-1]-1).astype(int) #corresponding to the signal label (i.e. load levels).\n",
    "print(np.shape(Label)) \n",
    "Patient_id = sio.loadmat(\"Sample Data/trials_subNums.mat\")['subjectNum'][0] #corresponding to the patient id\n",
    "print(np.shape(Patient_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading patient dataset \n",
    "From the total data, we select the images corresponding patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose among the patient : [ 1  2  3  4  6  7  8  9 10 11 12 14 15]\n"
     ]
    }
   ],
   "source": [
    "print(\"Choose among the patient : \"+str(np.unique(Patient_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "choosen_patient = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: BasicCNN\n",
    "First Implementation of a CNN on the Mean Images from each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part = 0.8\n",
    "test_part = 0.2\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset(label=Label[Patient_id==choosen_patient], image=Mean_Images[Patient_id==choosen_patient])\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training \n",
      " loss: 0.000\tAccuracy : 1.000\t\tval-loss: 0.236\tval-Accuracy : 0.975\n"
     ]
    }
   ],
   "source": [
    "res = TrainTest_Model(BasicCNN, Trainloader, Testloader, n_epoch=50, learning_rate=0.001, print_epoch=-1, opti='Adam', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxpool CNN\n",
    "Build the Max-pooling model performing a maxpool over the 7 parallel convnets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part = 0.8\n",
    "test_part = 0.2\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset_time(label=Label[Patient_id==choosen_patient], image=Images[:,Patient_id==choosen_patient,:,:,:])\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training for Patient 9\n",
      "[5,  45]\tloss: 0.705\tAccuracy : 0.630\t\tval-loss: 1.173\tval-Accuracy : 0.625\n",
      "[10,  45]\tloss: 0.132\tAccuracy : 0.932\t\tval-loss: 0.732\tval-Accuracy : 0.900\n",
      "[15,  45]\tloss: 0.239\tAccuracy : 0.914\t\tval-loss: 0.352\tval-Accuracy : 0.850\n",
      "[20,  45]\tloss: 0.034\tAccuracy : 0.994\t\tval-loss: 0.253\tval-Accuracy : 0.950\n",
      "[25,  45]\tloss: 0.001\tAccuracy : 1.000\t\tval-loss: 1.074\tval-Accuracy : 0.850\n",
      "[30,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 1.151\tval-Accuracy : 0.925\n",
      "[35,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 1.159\tval-Accuracy : 0.925\n",
      "[40,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 1.124\tval-Accuracy : 0.925\n",
      "[45,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 1.100\tval-Accuracy : 0.925\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training for Patient '+str(choosen_patient))\n",
    "res = TrainTest_Model(MaxCNN, Trainloader, Testloader, n_epoch=45, learning_rate=0.001, print_epoch=5, opti='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temp CNN\n",
    "FBuild the Conv1D model performing a convolution1D over the 7 parallel convnets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training for Patient 9\n",
      "[5,  45]\tloss: 0.435\tAccuracy : 0.821\t\tval-loss: 1.963\tval-Accuracy : 0.725\n",
      "[10,  45]\tloss: 0.240\tAccuracy : 0.895\t\tval-loss: 2.726\tval-Accuracy : 0.825\n",
      "[15,  45]\tloss: 0.001\tAccuracy : 1.000\t\tval-loss: 3.100\tval-Accuracy : 0.875\n",
      "[20,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 3.055\tval-Accuracy : 0.875\n",
      "[25,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 3.248\tval-Accuracy : 0.875\n",
      "[30,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 3.325\tval-Accuracy : 0.875\n",
      "[35,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 3.382\tval-Accuracy : 0.875\n",
      "[40,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 3.427\tval-Accuracy : 0.875\n",
      "[45,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 3.467\tval-Accuracy : 0.875\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training for Patient '+str(choosen_patient))\n",
    "res = TrainTest_Model(TempCNN, Trainloader, Testloader, n_epoch=45, learning_rate=0.001, print_epoch=5, opti='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM CNN\n",
    "Build the LSTM model applying a RNN over the 7 parallel convnets outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 7 but corresponding boolean dimension is 2670",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-165505f89736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mEEG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEEGImagesDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPatient_id\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mchoosen_patient\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPatient_id\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mchoosen_patient\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEEG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_part\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEEG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtest_part\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEEG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 7 but corresponding boolean dimension is 2670"
     ]
    }
   ],
   "source": [
    "EEG = EEGImagesDataset(label=Label[Patient_id==choosen_patient], image=Images[Patient_id==choosen_patient])\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset_time(label=Label[Patient_id==choosen_patient], image=Images[:,Patient_id==choosen_patient,:,:,:])\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training for Patient 9\n",
      "[5,  45]\tloss: 1.345\tAccuracy : 0.309\t\tval-loss: 1.376\tval-Accuracy : 0.200\n",
      "[10,  45]\tloss: 1.294\tAccuracy : 0.302\t\tval-loss: 1.361\tval-Accuracy : 0.275\n",
      "[15,  45]\tloss: 1.202\tAccuracy : 0.296\t\tval-loss: 1.367\tval-Accuracy : 0.300\n",
      "[20,  45]\tloss: 0.917\tAccuracy : 0.593\t\tval-loss: 1.055\tval-Accuracy : 0.525\n",
      "[25,  45]\tloss: 0.672\tAccuracy : 0.685\t\tval-loss: 0.913\tval-Accuracy : 0.575\n",
      "[30,  45]\tloss: 0.526\tAccuracy : 0.784\t\tval-loss: 0.809\tval-Accuracy : 0.600\n",
      "[35,  45]\tloss: 0.388\tAccuracy : 0.864\t\tval-loss: 0.746\tval-Accuracy : 0.650\n",
      "[40,  45]\tloss: 0.286\tAccuracy : 0.926\t\tval-loss: 0.959\tval-Accuracy : 0.625\n",
      "[45,  45]\tloss: 0.195\tAccuracy : 0.957\t\tval-loss: 0.746\tval-Accuracy : 0.650\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training for Patient '+str(choosen_patient))\n",
    "res = TrainTest_Model(LSTM, Trainloader, Testloader, n_epoch=45, learning_rate=0.0001, print_epoch=5, opti='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mix CNN\n",
    "Build the LSTM model applying a RNN and a CNN over the 7 parallel convnets outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset_time(label=Label[Patient_id==choosen_patient], image=Images[:,Patient_id==choosen_patient,:,:,:])\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training for Patient 9\n",
      "[5,  60]\tloss: 1.368\tAccuracy : 0.302\t\tval-loss: 1.385\tval-Accuracy : 0.300\n",
      "[10,  60]\tloss: 1.352\tAccuracy : 0.296\t\tval-loss: 1.387\tval-Accuracy : 0.250\n",
      "[15,  60]\tloss: 1.340\tAccuracy : 0.302\t\tval-loss: 1.389\tval-Accuracy : 0.275\n",
      "[20,  60]\tloss: 1.311\tAccuracy : 0.531\t\tval-loss: 1.369\tval-Accuracy : 0.500\n",
      "[25,  60]\tloss: 1.196\tAccuracy : 0.377\t\tval-loss: 1.276\tval-Accuracy : 0.375\n",
      "[30,  60]\tloss: 1.046\tAccuracy : 0.525\t\tval-loss: 1.147\tval-Accuracy : 0.525\n",
      "[35,  60]\tloss: 0.903\tAccuracy : 0.556\t\tval-loss: 1.025\tval-Accuracy : 0.500\n",
      "[40,  60]\tloss: 0.786\tAccuracy : 0.605\t\tval-loss: 0.932\tval-Accuracy : 0.525\n",
      "[45,  60]\tloss: 0.672\tAccuracy : 0.673\t\tval-loss: 0.838\tval-Accuracy : 0.600\n",
      "[50,  60]\tloss: 0.520\tAccuracy : 0.778\t\tval-loss: 0.706\tval-Accuracy : 0.725\n",
      "[55,  60]\tloss: 0.347\tAccuracy : 0.901\t\tval-loss: 0.556\tval-Accuracy : 0.775\n",
      "[60,  60]\tloss: 0.221\tAccuracy : 0.932\t\tval-loss: 0.430\tval-Accuracy : 0.850\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training for Patient '+str(choosen_patient))\n",
    "res = TrainTest_Model(Mix, Trainloader, Testloader, n_epoch=60, learning_rate=0.00001, print_epoch=5, opti='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p36",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
